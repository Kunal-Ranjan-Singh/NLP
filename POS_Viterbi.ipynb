{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNC-Y3s9tu4q",
        "outputId": "4a78a798-9ba6-4c01-f16b-d8ad918bf35a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: This is implementation example of viterbi algorithm\n",
            "+----------------+-----------+\n",
            "| Word           | POS Tag   |\n",
            "+================+===========+\n",
            "| This           | DET       |\n",
            "+----------------+-----------+\n",
            "| is             | VERB      |\n",
            "+----------------+-----------+\n",
            "| implementation | NOUN      |\n",
            "+----------------+-----------+\n",
            "| example        | NOUN      |\n",
            "+----------------+-----------+\n",
            "| of             | NOUN      |\n",
            "+----------------+-----------+\n",
            "| viterbi        | NOUN      |\n",
            "+----------------+-----------+\n",
            "| algorithm      | NOUN      |\n",
            "+----------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "from nltk.corpus import treebank\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Download the required corpus\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "# Load the dataset\n",
        "data = list(treebank.tagged_sents(tagset='universal'))\n",
        "\n",
        "# Split into training and test sets\n",
        "train_data = data[:3000]\n",
        "test_data = data[3000:]\n",
        "\n",
        "# Train the HMM model\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagging_model = trainer.train(train_data)\n",
        "\n",
        "# Take user input\n",
        "user_sentence = input(\"Enter a sentence: \").split()\n",
        "\n",
        "# Perform POS tagging\n",
        "predicted_tags = tagging_model.tag(user_sentence)\n",
        "\n",
        "# Output result in tabular form\n",
        "print(tabulate(predicted_tags, headers=[\"Word\", \"POS Tag\"], tablefmt=\"grid\"))\n",
        "\n",
        "\n"
      ]
    }
  ]
}