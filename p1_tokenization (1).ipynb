{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVDsrMmbdI-B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=['Kunal is a student','NLP is a subject','Kunal excles NLP']"
      ],
      "metadata": {
        "id": "bXiyeS5hfvGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(num_words=100,oov_token=\"<oov>\")"
      ],
      "metadata": {
        "id": "_Q-T3h10dbgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(data)"
      ],
      "metadata": {
        "id": "-SUZ5nPIgfAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word Tokenization:\")\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDwEzuHgDk2",
        "outputId": "feb37089-5545-4ede-ec1c-90a0774e9ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization:\n",
            "{'<oov>': 1, 'kunal': 2, 'is': 3, 'a': 4, 'nlp': 5, 'student': 6, 'subject': 7, 'excles': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen=tokenizer.texts_to_sequences(data)\n",
        "print(\"Sentence Tokenization:\")\n",
        "print(sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylA9dBH6gVrS",
        "outputId": "2a5454f5-0408-4b87-e3a1-cb76112c9b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization:\n",
            "[[2, 3, 4, 6], [5, 3, 4, 7], [2, 8, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=['NLP is a subject excelled by Kunal', 'Kunal is a student']"
      ],
      "metadata": {
        "id": "raCt3wJDiCKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen=tokenizer.texts_to_sequences(test)\n",
        "print(sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6vCEDDuiPh0",
        "outputId": "9568c967-6ba1-4694-aa82-02a6953daef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 3, 4, 7, 1, 1, 2], [2, 3, 4, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded=pad_sequences(sen)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxIVCsv4iUcE",
        "outputId": "a09abecb-3e25-4681-d6f7-e3cfb2bfd3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5 3 4 7 1 1 2]\n",
            " [0 0 0 2 3 4 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "wHMQiphdAPBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_second=\"Kunal is a student NLP is a subject Kunal excels NLP\""
      ],
      "metadata": {
        "id": "40m_lBlsAO2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "regexp_tokens = regexp_tokenize(data_second, pattern=r'\\b\\w+\\b')\n",
        "print(\"RegExp Tokenization:\")\n",
        "print(regexp_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWsKrJfSAOrb",
        "outputId": "d2623bae-1b75-4d55-e4b5-81b40e6bec18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegExp Tokenization:\n",
            "['Kunal', 'is', 'a', 'student', 'NLP', 'is', 'a', 'subject', 'Kunal', 'excels', 'NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(data_second)\n",
        "print(\"Tweet Tokenization:\")\n",
        "print(tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWqjQt_pAOf0",
        "outputId": "353b1f88-67c9-48ea-ca0f-bea1b8344676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Tokenization:\n",
            "['Kunal', 'is', 'a', 'student', 'NLP', 'is', 'a', 'subject', 'Kunal', 'excels', 'NLP']\n"
          ]
        }
      ]
    }
  ]
}